{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da2cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import json\n",
    "from sklearn import linear_model\n",
    "import sklearn\n",
    "import csv\n",
    "import gzip\n",
    "import string\n",
    "import copy\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d439cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpful functions\n",
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rb'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98daec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the data\n",
    "reviewSmall = [] #Users and a list of games they have reviewed\n",
    "userToItem = [] #Users and a list of games they have downloaded\n",
    "#User id's ^ directly correlated \n",
    "\n",
    "reviewBig = [] #Random assortment of reviews \n",
    "itemMetaData = [] #Data about each individual game\n",
    "bundleData = [] #Data about each bundle\n",
    "for d in readGz('../australian_user_reviews.json.gz'):\n",
    "    reviewSmall.append(d)\n",
    "    \n",
    "for d in readGz('../australian_users_items.json.gz'):\n",
    "    userToItem.append(d)\n",
    "    \n",
    "for d in readGz('../bundle_data.json.gz'):\n",
    "    bundleData.append(d)\n",
    "    \n",
    "for d in readGz('../steam_games.json.gz'):\n",
    "    itemMetaData.append(d)\n",
    "\n",
    "# i = 0\n",
    "# for d in readGz('../steam_reviews.json.gz'):\n",
    "#     if i < 50000:\n",
    "#         reviewBig.append(d)\n",
    "#     else:\n",
    "#         break\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "52e99084",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantUserToItem = []\n",
    "for u in userToItem:\n",
    "    if len(u['items'])>=2:\n",
    "        relevantUserToItem.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d9a1a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and test sets\n",
    "train=[]\n",
    "test=[]\n",
    "lengths=[]\n",
    "item_lens=[]\n",
    "for user in relevantUserToItem:\n",
    "    items = user['items']\n",
    "    trainIndex = round(0.7*len(items))\n",
    "    item_lens.append(len(items))\n",
    "    lengths.append(len(items)-round(0.7*len(items)))\n",
    "    items_train = items[:trainIndex]\n",
    "    items_test = items[trainIndex:]\n",
    "    objTrain = {'user_id':user['user_id'], 'items': items_train}\n",
    "    objTest = {'user_id':user['user_id'], 'items': items_test}\n",
    "    train.append(objTrain)\n",
    "    test.append(objTest)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055de2f3",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "2570b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemHours = defaultdict(int)\n",
    "for user in train:\n",
    "    for item in user['items']:\n",
    "        itemHours[item['item_id']]+=float(item['playtime_forever'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c1392286",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPopular = [(itemHours[x], x) for x in itemHours]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "top20recs = [i[1] for i in mostPopular[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ee3da57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions=[]\n",
    "for i, d in enumerate(test):\n",
    "    currec = top20recs\n",
    "    userid = d['user_id']\n",
    "    userTestItems = ItemsForUserTest[userid]\n",
    "    precisions.append(len(userTestItems.intersection(currec))/len(currec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e5922619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(precisions)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd540aaf",
   "metadata": {},
   "source": [
    "## Predictions with Jaccard using the user reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa95360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0c08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemsForUser=defaultdict(set)\n",
    "for user in train:\n",
    "    for item in user['items']:\n",
    "        ItemsForUser[user['user_id']].add(item['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2924bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "UsersForItem = defaultdict(set)\n",
    "for user in train:\n",
    "    for item in user['items']:\n",
    "        UsersForItem[item['item_id']].add(user['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9780e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "Top10ItemsForUser=defaultdict(list)\n",
    "for d in train:\n",
    "    user_id = d['user_id']\n",
    "    items = d['items']\n",
    "    items.sort(key=lambda x: x['playtime_forever'], reverse = True)\n",
    "    itemids = [d['item_id'] for d in items]\n",
    "    Top10ItemsForUser[user_id] = itemids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de37b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(u, N):\n",
    "    similarities = []\n",
    "    items = set(Top10ItemsForUser[u])\n",
    "    for u2 in ItemsForUser:\n",
    "        if u2 == u: continue\n",
    "        sim = Jaccard(items, set(Top10ItemsForUser[u2]))\n",
    "        similarities.append((sim,u2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return [u[1] for u in similarities[:N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15bb956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5SimilarUsers = defaultdict(list)\n",
    "for d in train[:1000]:\n",
    "    user_id = d['user_id']\n",
    "    top5SimilarUsers[user_id] = mostSimilar(user_id, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "33068e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(top5SimilarUsers)\n",
    "# df.to_csv('MostSimilarUsersfirst1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5146cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('MostSimilarUsersfirst1000.csv')\n",
    "data=data.T.drop('Unnamed: 0')\n",
    "top5SimilarUsers = data.apply(lambda x: list([x[0], x[1], x[2], x[3], x[4]]),axis=1).to_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cb91a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemsForUserTest=defaultdict(set)\n",
    "for user in test:\n",
    "    for item in user['items']:\n",
    "        ItemsForUserTest[user['user_id']].add(item['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "69324a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5SimilarUsersTest = defaultdict(list)\n",
    "recommendations=[]\n",
    "reclengths = []\n",
    "for d in test[:1000]:\n",
    "    userid = d['user_id']\n",
    "    top5similar = top5SimilarUsers[userid]\n",
    "    top50recs = Top10ItemsForUser[top5similar[0]]+Top10ItemsForUser[top5similar[1]]+Top10ItemsForUser[top5similar[2]]+Top10ItemsForUser[top5similar[3]]+Top10ItemsForUser[top5similar[4]]\n",
    "    potentialrecs = set(top50recs)-ItemsForUser[userid]\n",
    "    reclengths.append(len(potentialrecs))\n",
    "    if len(potentialrecs)>20:\n",
    "        potentialrecs = set(random.sample(potentialrecs, 20))\n",
    "    recommendations.append(potentialrecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "180fbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions=[]\n",
    "for i, d in enumerate(test[:30]):\n",
    "    currec = recommendations[i]\n",
    "    userid = d['user_id']\n",
    "    userTestItems = ItemsForUserTest[userid]\n",
    "    precisions.append(len(userTestItems.intersection(currec))/len(currec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aaa32732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(precisions)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3ca74",
   "metadata": {},
   "source": [
    "## Predictions with Pearson using the Steam Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d21fe407",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewBig = []\n",
    "for i, d in enumerate(readGz('../steam_reviews.json.gz')):\n",
    "    reviewBig.append(d)\n",
    "    if i==500000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2efc6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPearson = reviewBig[:300000]\n",
    "testPearson = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5fc9647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in reviewBig[300000:]:\n",
    "    if t['username'] in trainUsers:\n",
    "        testPearson.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b4af9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsPerUser2 = defaultdict(set)\n",
    "\n",
    "for user in trainPearson:\n",
    "    username, item = user['username'], user['product_id']\n",
    "    itemsPerUser2[username].add(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "eaca584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRelevant = []\n",
    "trainUsers = set()\n",
    "itemsPerUserWithHours = defaultdict(list)\n",
    "usersPerItemPearson = defaultdict(set)\n",
    "itemsPerUserPearson = defaultdict(set)\n",
    "\n",
    "for u in trainPearson:\n",
    "    if len(itemsPerUser2[u['username']])>=2:\n",
    "        try:\n",
    "            hours = float(u['hours'])\n",
    "            username, item = u['username'], u['product_id']\n",
    "            trainRelevant.append(u)\n",
    "            trainUsers.add(u['username'])\n",
    "            usersPerItemPearson[item].add(username)\n",
    "            itemsPerUserPearson[username].add(item)\n",
    "            itemsPerUserWithHours[username].append({'item_id':item, 'hours':hours})\n",
    "            rating=0       \n",
    "            if hours>=50:\n",
    "                rating=5\n",
    "            elif hours>=20:\n",
    "                rating=4\n",
    "            elif hours>=8:\n",
    "                rating=3\n",
    "            elif hours>=2:\n",
    "                rating=2\n",
    "            elif hours>=0:\n",
    "                rating=1\n",
    "            ratingDict[(username,item)] = rating\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b53e812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testRelevant=[]\n",
    "for t in testPearson:\n",
    "    if t['username'] in trainUsers:\n",
    "        testRelevant.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9642fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "userAverages = {}\n",
    "itemAverages = {}\n",
    "\n",
    "for u in itemsPerUserPearson:\n",
    "    rs = [ratingDict[(u,i)] for i in itemsPerUserPearson[u]]\n",
    "    userAverages[u] = sum(rs) / len(rs)\n",
    "    \n",
    "for i in usersPerItemPearson:\n",
    "    rs = [ratingDict[(u,i)] for u in usersPerItemPearson[i]]\n",
    "    itemAverages[i] = sum(rs) / len(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "01137e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson(u1, u2):\n",
    "    # Between two users\n",
    "    iBar1 = userAverages[u1]\n",
    "    iBar2 = userAverages[u2]\n",
    "    inter = itemsPerUserPearson[u1].intersection(itemsPerUserPearson[u2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    for i in inter:\n",
    "        numer += (ratingDict[(u1,i)] - iBar1)*(ratingDict[(u2,i)] - iBar2)\n",
    "    for i1 in itemsPerUserPearson[u1]:\n",
    "        denom1 += (ratingDict[(u1,i1)] - iBar1)**2\n",
    "    for i2 in itemsPerUserPearson[u2]:\n",
    "        denom2 += (ratingDict[(u2,i2)] - iBar2)**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e9ff245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarPearson(u, N):\n",
    "    similarities = []\n",
    "    items = itemsPerUserPearson[u]\n",
    "    for u2 in list(itemsPerUserPearson.keys()):\n",
    "        if u2 == u: continue\n",
    "        sim = Pearson(u, u2)\n",
    "        #sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,u2))\n",
    "    similarities.sort(reverse=True)\n",
    "#     return similarities[:N]\n",
    "    return [u[1] for u in similarities[:N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ad78eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100test = testRelevant[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "02fd7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10SimilarUsersPearson = defaultdict(list)\n",
    "for user in top100test:\n",
    "    user_id = user['username']\n",
    "    top10SimilarUsersPearson[user_id] = mostSimilarPearson(user_id, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "7b45f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemsForUserTestPearson=defaultdict(set)\n",
    "for user in testRelevant:\n",
    "    ItemsForUserTestPearson[user['username']].add(user['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "6a402bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Top10ItemsForUser=defaultdict(list)\n",
    "for user_id in list(itemsPerUserWithHours.keys()):\n",
    "    items = itemsPerUserWithHours[user_id]\n",
    "    items.sort(key=lambda x: x['hours'], reverse = True)\n",
    "    itemids = [d['item_id'] for d in items]\n",
    "    Top10ItemsForUser[user_id] = itemids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "70d92ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations=[]\n",
    "reclengths = []\n",
    "for user in top100test:\n",
    "    user_id = user['username']\n",
    "    topsimilar = top10SimilarUsersPearson[user_id]\n",
    "    toprecs = []\n",
    "    for user in topsimilar:\n",
    "        toprecs=toprecs+Top10ItemsForUser[user]\n",
    "        \n",
    "    potentialrecs = set(toprecs)-itemsPerUserPearson[user_id]\n",
    "    reclengths.append(len(potentialrecs))\n",
    "    if len(potentialrecs)>20:\n",
    "        potentialrecs = set(random.sample(potentialrecs, 20))\n",
    "    recobj = {'user_id':user_id, 'recommendations':potentialrecs}\n",
    "    recommendations.append(recobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "55dd33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisionsPearson=[]\n",
    "for r in recommendations:\n",
    "    items=ItemsForUserTestPearson[r['user_id']]\n",
    "    if len(r['recommendations'])==0:\n",
    "        precisionsPearson.append(0)\n",
    "    else:\n",
    "        precisionsPearson.append(len(set(items).intersection(r['recommendations']))/len(r['recommendations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "2b6fb6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(precisionsPearson)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1cbe47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
